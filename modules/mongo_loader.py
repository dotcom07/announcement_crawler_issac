import os
import json
from pymongo import MongoClient
from datetime import datetime
from pytz import timezone

import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../")))
from config.site_config import SITES  # SITESì—ì„œ source ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

# MongoDB ì„¤ì •
MONGO_URI = "mongodb+srv://admin:!dkdlwkr03@cluster0.y0emv.mongodb.net/"
DB_NAME = "isaac"
CRAWLER_COLLECTION = "crawler_states"
OUTPUT_DIR = "output/crawler_state/"

KST = timezone('Asia/Seoul')



def save_crawler_states_to_files():
    """
    MongoDBì—ì„œ í¬ë¡¤ëŸ¬ ìƒíƒœ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ê° sourceë³„ JSON íŒŒì¼ë¡œ ì €ì¥
    ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ í›„ ì €ì¥
    """
    client = MongoClient(MONGO_URI)
    db = client[DB_NAME]
    collection = db[CRAWLER_COLLECTION]

    os.makedirs(OUTPUT_DIR, exist_ok=True)  # ì¶œë ¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´)

    for source in SITES.keys():  # SITESì—ì„œ source ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        state_data = collection.find_one({"source": source}, {"_id": 0})

        if not state_data:
            print(f"[INFO] No data found for {source}. Skipping...")
            continue  # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì €ì¥í•˜ì§€ ì•ŠìŒ

        # ğŸ”¹ datetimeì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        if "updated_at" in state_data and isinstance(state_data["updated_at"], datetime):
            state_data["updated_at"] = state_data["updated_at"].isoformat()

        file_path = os.path.join(OUTPUT_DIR, f"announcement_state_{source}.json")

        # âœ… ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
        if os.path.exists(file_path):
            os.remove(file_path)

        # âœ… ë°ì´í„°ê°€ `PSYCHOLOGY`ì¼ ê²½ìš° article_idsë§Œ ì €ì¥
        if source == "PSYCHOLOGY":
            file_path = os.path.join(OUTPUT_DIR, "article_ids_PSYCHOLOGY.txt")
            article_ids = state_data.get("article_ids", [])

            if os.path.exists(file_path):
                os.remove(file_path)

            with open(file_path, "w", encoding="utf-8") as f:
                for article_id in article_ids:
                    f.write(f"{article_id}\n")

            print(f"[INFO] {source} article IDs saved to {file_path}")

        # âœ… ë°ì´í„°ê°€ `ARCHITECTURE_ENGINEERING`ì¼ ê²½ìš° JSON ì €ì¥
        elif source == "ARCHITECTURE_ENGINEERING":
            file_path = os.path.join(OUTPUT_DIR, "announcement_state_ARCHITECTURE_ENGINEERING.json")

            if os.path.exists(file_path):
                os.remove(file_path)

            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(state_data, f, indent=4, ensure_ascii=False)

            print(f"[INFO] {source} state saved to {file_path}")

        # âœ… ì¼ë°˜ í¬ë¡¤ëŸ¬ ë°ì´í„° ì €ì¥
        else:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(state_data, f, indent=4, ensure_ascii=False)

            print(f"[INFO] {source} state saved to {file_path}")

    client.close()




if __name__ == "__main__":
    os.makedirs(OUTPUT_DIR, exist_ok=True)  # ì¶œë ¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´)
    save_crawler_states_to_files()
